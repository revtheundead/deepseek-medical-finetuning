{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Credits\n\nThis notebook and this code is a fork of Abid Ali Awan's tutorial on [Fine-Tuning DeepSeek R1](https://www.datacamp.com/tutorial/fine-tuning-deepseek-r1-reasoning-model).\n\n\n## Which tools & packages will we be using?\n\nPackages we're going to be using throughout this project\n\n- `unsloth`: Efficient fine-tuning and inference for LLMs — Specifically we will be using:\n    - `FastLanguageModel` module to optimize inference & fine-tuning\n    - `get_peft_model` to enable LoRa (Low-Rank Adaptation) fine-tuning\n- `peft`: Supports LoRA-based fine-tuning for large models.\n- Different Hugging Face modules:\n    - `transformers` from HuggingFace to work with our fine-tuning data and handle different model tasks\n    - `trl` Transformer Reinforcement Learning from HuggingFace which allows for supervised fine-tuning of the model — we will use the `SFFTrainer` wrapper\n    - `datasets` to fetch reasoning datasets from the Hugging Face Hub\n- `torch`: Deep learning framework used for training\n- `wandb`: Provides access to weights and biases for tracking our fine-tuning experiment ","metadata":{}},{"cell_type":"markdown","source":"## Before we get started — how to access the Hugging Face and Weights & Biases API\n\n### Set GPU accelerator\nWe are using Kaggle Notebooks because we have access to free GPUs. To enable GPU access, press on Settings > Accelerator > GPU T4 x2\n\n### How to access the Hugging Face API\n\n1. Register to Huggin Face if you have not already\n2. Go to [Hugging Face Tokens](https://huggingface.co/settings/tokens).\n3. Click **\"New Token\"**.\n4. Select **read/write** permissions if needed.\n5. Copy your **API key**.\n\n### Weights & Biases API key**\n1. Sign up at [Weights & Biases](https://wandb.ai/site).\n2. Go to [W&B Settings](https://wandb.ai/settings).\n3. Copy your **API key** from the \"API Keys\" section.\n\n### Add the API keys to Kaggle Notebooks\n1. Press on Add-ons > Secrets\n2. Add the API keys under `Hugging_Face_Token` and `wnb` respectively\n\nYou can now use this code to retrieve your API keys\n\n```py\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhugging_face_token = user_secrets.get_secret(\"Hugging_Face_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n```","metadata":{}},{"cell_type":"markdown","source":"## Install relevant packages","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:07:58.808481Z","iopub.execute_input":"2025-02-08T12:07:58.808788Z","iopub.status.idle":"2025-02-08T12:11:16.181453Z","shell.execute_reply.started":"2025-02-08T12:07:58.808765Z","shell.execute_reply":"2025-02-08T12:11:16.180454Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Import packages","metadata":{}},{"cell_type":"code","source":"# Modules for fine-tuning\nfrom unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\nfrom trl import SFTTrainer\nimport torch\n\n# Hugging Face modules\nfrom huggingface_hub import login\nfrom transformers import TrainingArguments\nfrom datasets import load_dataset\n\n# Import weights and biases\nimport wandb\n\n# Import secrets\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:11:20.886694Z","iopub.execute_input":"2025-02-08T12:11:20.886982Z","iopub.status.idle":"2025-02-08T12:11:49.273449Z","shell.execute_reply.started":"2025-02-08T12:11:20.886962Z","shell.execute_reply":"2025-02-08T12:11:49.272555Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Get the API keys and login to both HuggingFace and Weights and Biases","metadata":{}},{"cell_type":"code","source":"# Initialize Hugging Face and W&B tokens\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n\n# Login to HuggingFace\nlogin(hf_token)\n\n# Login to W&B\nwandb.login(key=wnb_token)\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Medical COT Dataset',\n    job_type='training',\n    anonymous='allow'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:11:49.274595Z","iopub.execute_input":"2025-02-08T12:11:49.274883Z","iopub.status.idle":"2025-02-08T12:12:02.468839Z","shell.execute_reply.started":"2025-02-08T12:11:49.274847Z","shell.execute_reply":"2025-02-08T12:12:02.468199Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33muozbek\u001b[0m (\u001b[33muozbek-havelsan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250208_121156-ozw6z49o</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/ozw6z49o' target=\"_blank\">smart-wildflower-2</a></strong> to <a href='https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/ozw6z49o' target=\"_blank\">https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/ozw6z49o</a>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Loading DeepSeek R1 and the Tokenizer\n#### What are we trying to do here?\nIn this step, we **load the DeepSeek R1 model and its tokenizer** using `FastLanguageModel.from_pretrained()`. We also configure some key parameters for better fine-tuning. We will be using a distilled 8B version of R1 for faster computation.\n\n#### What are the key parameters?\n```python\n    max_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. number of tokens per input)\n    dtype = None # Default data type (usually auto-detected)\n    load_in_4bit = True # Enables 4-bit quantization. This is a memory-saving optimization\n```\n\n#### Why 4-bit quantization?\nImagine compressing a **high-resolution image** to a smaller size-it takes up less space but still looks decent. Similarly, 4-bit quantization reduces the precision of model weights, making the model **smaller and faster while keeping most of its accuracy**. Instead of storing **32-bit or 16-bit numbers**, we compress them into **4-bit values**. This allows LLMs to **run efficiently on consumer GPUs** without needing too much memory.","metadata":{}},{"cell_type":"code","source":"# Set parameters\nmax_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. number of tokens per input)\ndtype = None # Default data type (usually auto-detected)\nload_in_4bit = True # Enables 4-bit quantization. This is a memory-saving optimization\n\n# Load the DeepSeek R1 model and tokenizer using unsloth - imported using: from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name='unsloth/DeepSeek-R1-Distill-Llama-8B', # Load the pre-trained DeepSeek R1 model (8B parameter version)\n    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n    token=hf_token # Use the HuggingFace token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:12:18.968056Z","iopub.execute_input":"2025-02-08T12:12:18.968384Z","iopub.status.idle":"2025-02-08T12:12:47.124962Z","shell.execute_reply.started":"2025-02-08T12:12:18.968359Z","shell.execute_reply":"2025-02-08T12:12:47.124335Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.4: Fast Llama patching. Transformers: 4.48.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e96f15f5c24c549cfdd30538acf04e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a10c56b4ca14737a7c8f396dda5fb1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a63e6b47df5844a5bf98af2903d8c265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef94ef2d1c8499ab00b8b2f1c026406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc723606d3b341eab7b36250296848c9"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Testing DeepSeek R1 on a medical use-case before proceeding with fine-tuning\n#### Defining a system prompt\nTo create a prompt style for the model, we will be defining a system prompt. We will include placeholders for the question and response generation. The prompt will guide the model to think step-by-step and provide a logical response.","metadata":{}},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, carefully analyze the question and construct a clear, step-by-step chain of reasoning to ensure a logical, accurate, and well-supported response.\n\n### Instruction:\nYou are a highly knowledgeable medical expert with advanced expertise in clinical reasoning, diagnostics, and treatment planning. \nProvide a precise and well-structured answer to the following medical question, ensuring clarity and evidence-based reasoning.\n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:12:51.310389Z","iopub.execute_input":"2025-02-08T12:12:51.310686Z","iopub.status.idle":"2025-02-08T12:12:51.315592Z","shell.execute_reply.started":"2025-02-08T12:12:51.310665Z","shell.execute_reply":"2025-02-08T12:12:51.314856Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Running inference on the model\nIn this step, we test the R1 model by providing a medical question and generating a response. The process involves the following steps:\n\n1. Define a test question related to a medical case.\n2. Format the question using the structured prompt (`prompt_style`) to ensure the model follows a logical reasoning process.\n3. Tokenize the input and move it to the GPU (`cuda`)** for faster inference.\n4. Generate a response using the model, specifying key parameters like `max_new_tokens=1200` (limits response length).\n5. Decode the output tokens back into text to obtain the final readable answer.","metadata":{}},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"A 45-year-old man presents with progressive difficulty swallowing both solids and liquids over the past \n              six months. He reports occasional regurgitation of undigested food and a sensation of food sticking in his \n              chest. A barium swallow study reveals a dilated esophagus with a bird’s beak appearance at the lower \n              esophageal sphincter. What would esophageal manometry most likely demonstrate regarding lower esophageal \n              sphincter pressure and peristalsis?\"\"\"\n\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency)\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=1200, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response[0].split(\"### Response:\")[1])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:12:56.072726Z","iopub.execute_input":"2025-02-08T12:12:56.073053Z","iopub.status.idle":"2025-02-08T12:13:37.691224Z","shell.execute_reply.started":"2025-02-08T12:12:56.073025Z","shell.execute_reply":"2025-02-08T12:13:37.690378Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I'm trying to figure out what esophageal manometry would show in this case. Let me start by going through the information given.\n\nThe patient is a 45-year-old man with progressive difficulty swallowing solids and liquids for six months. He also reports occasional regurgitation of undigested food and a sensation of food sticking in his chest. The barium swallow study showed a dilated esophagus with a bird’s beak appearance at the lower esophageal sphincter.\n\nHmm, dilated esophagus with a bird’s beak at the lower sphincter. I remember that the lower esophageal sphincter (LES) is the gatekeeper between the esophagus and stomach. If there's a bird’s beak appearance, that probably means there's some kind of narrowing or structure there. Maybe it's a strictured area or a functional obstruction.\n\nThe symptoms include dysphagia (difficulty swallowing) and regurgitation of undigested food, which suggests that things aren't moving smoothly from the esophagus into the stomach. The sensation of food sticking in the chest could be due to incomplete relaxation of the LES or maybe some obstruction.\n\nNow, thinking about esophageal manometry. This test measures pressure in the esophagus and how well it moves (peristalsis). Normally, the LES should relax when food comes in and contract when it's not. If there's a problem, like a strictured LES, the manometry might show high pressure there because the sphincter is resisting opening. This would cause the esophageal pressure to be higher than normal when trying to push food through, leading to difficulty swallowing.\n\nAlso, if the peristalsis is impaired, the esophageal muscles might not move properly, contributing to the regurgitation and dysphagia. But in this case, the main finding from the barium swallow is the LES structure, so the manometry would likely highlight the elevated pressure at the LES, not the peristalsis itself.\n\nWait, but the question specifically asks about both lower esophageal sphincter pressure and peristalsis. So maybe both aspects are relevant. High pressure at the LES would cause the esophageal muscles to work harder, which could lead to impaired peristalsis if the muscles are fatigued. Or maybe the peristalsis is normal, but the obstruction at the LES is the main issue.\n\nI think the key here is that the manometry would show increased LES pressure, indicating that the sphincter is not relaxing properly. This would explain the difficulty in swallowing and the regurgitation because the food can't pass through the LES easily.\n</think>\n\nEsophageal manometry in this case would most likely demonstrate **elevated lower esophageal sphincter (LES) pressure**. This increase in pressure at the LES is consistent with the findings from the barium swallow study, which revealed a bird’s beak appearance, suggesting a functional or structural obstruction at the LES level. Such an elevation in pressure may indicate that the sphincter is not relaxing adequately, contributing to the difficulty in swallowing (dysphagia) and the regurgitation of undigested food. While the peristalsis (esophageal muscle contractions) may not be significantly impaired in this scenario, the primary abnormality appears to be related to the elevated LES pressure.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Before moving on, why would we need fine-tuning at all?\nEven without fine-tuning, R1 was able to generate a structured chain of thought and present reasoning before arriving at the final answer. This reasoning process is enclosed within the <think> </think> tags. So, why is fine-tuning still necessary? While the model's reasoning is thorough, it tends to be overly verbose rather than concise. Moreover, we aim to ensure that the final response maintains a consistent style.\n\n## Fine-tuning step-by-step\n### Step 1 - Update the system prompt\nWe will slightly change the prompt style for processing the dataset by adding the third placeholder for the complex chain of thought column `</think>`","metadata":{}},{"cell_type":"code","source":"# Updated training prompt style to add </think> tag \ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides additional context. \nGenerate a response that fully addresses the request with logical reasoning and medical expertise. \nBefore answering, carefully analyze the question and construct a step-by-step chain of thoughts to ensure clarity, accuracy, and coherence.\n\n### Instruction:\nYou are a highly skilled medical expert with deep expertise in clinical reasoning, diagnostics, and treatment planning. \nProvide a well-structured, evidence-based response to the following medical question.\n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:14:00.055988Z","iopub.execute_input":"2025-02-08T12:14:00.056347Z","iopub.status.idle":"2025-02-08T12:14:00.061341Z","shell.execute_reply.started":"2025-02-08T12:14:00.056314Z","shell.execute_reply":"2025-02-08T12:14:00.060537Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Step 2 - Download the fine-tuning dataset and format it for fine-tuning\nWe will use the Medical O1 Reasoning SFT found [here](https://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT) on HuggingFace. From the authors: This dataset is used to fine-tune HuatuoGPT-o1, a medical LLM designed for advanced medical reasoning. This dataset is constructed using GPT-4o, which searches for solutions to verifiable medical problems and validates them through a medical verifier.","metadata":{}},{"cell_type":"code","source":"# Download the dataset using Hugging Face — function imported using from datasets import load_dataset\ndataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train[0:500]\",trust_remote_code=True) # Keep only first 500 rows\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:14:02.804067Z","iopub.execute_input":"2025-02-08T12:14:02.804423Z","iopub.status.idle":"2025-02-08T12:14:06.655484Z","shell.execute_reply.started":"2025-02-08T12:14:02.804395Z","shell.execute_reply":"2025-02-08T12:14:06.654635Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"febd28d404bb4c6097e2932d4cecadc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/74.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f99761fb34fc44f3982796a653036db7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25371 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3df4058a224f17994f2ae52289d702"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Complex_CoT', 'Response'],\n    num_rows: 500\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Show an entry from the dataset\ndataset[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:14:12.965367Z","iopub.execute_input":"2025-02-08T12:14:12.965687Z","iopub.status.idle":"2025-02-08T12:14:12.974032Z","shell.execute_reply.started":"2025-02-08T12:14:12.965662Z","shell.execute_reply":"2025-02-08T12:14:12.973162Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'Question': 'A 45-year-old man with a history of alcohol use, who has been abstinent for the past 10 years, presents with sudden onset dysarthria, shuffling gait, and intention tremors. Given this clinical presentation and history, what is the most likely diagnosis?',\n 'Complex_CoT': \"Alright, let’s break this down. We have a 45-year-old man here, who suddenly starts showing some pretty specific symptoms: dysarthria, shuffling gait, and those intention tremors. This suggests something's going wrong with motor control, probably involving the cerebellum or its connections.\\n\\nNow, what's intriguing is that he's had a history of alcohol use, but he's been off it for the past 10 years. Alcohol can do a number on the cerebellum, leading to degeneration, and apparently, the effects can hang around or even appear long after one stops drinking.\\n\\nAt first glance, these symptoms look like they could be some kind of chronic degeneration, maybe something like alcoholic cerebellar degeneration, but hold on. This looks different. The symptoms just came on all of a sudden. Chronic degenerations typically have a more gradual onset.\\n\\nOkay, let’s reconsider this sudden nature. It’s making me think of something more acute, more rapid onset. Hmm, if we dig back into his history of drinking, there might have been some damage done, leading to nutritional deficiencies, like a lack of thiamine.\\n\\nWernicke’s encephalopathy is a classic possibility here. That condition pops up due to thiamine deficiency, often after a history of alcohol use. It’s known for causing ataxia, confusion, and eye movement issues. However, he’s not showing the full triad of symptoms; there's no mention of confusion or eye problems, so maybe it doesn’t fit perfectly.\\n\\nOh, wait a second, maybe we're missing something simpler. Given the acute nature of the symptoms, maybe this is more in line with something like a stroke. Sudden onset can definitely suggest a vascular event. With his alcohol history, he’s at risk for things like high blood pressure, which can increase stroke risk.\\n\\nIn particular, lacunar strokes can mess with motor coordination, speech, the works. These are small, but significant enough to cause these exact symptoms: dysarthria, tremors, and a shuffling gait.\\n\\nBut hang on, what if there’s another angle we’re missing? Chronic alcohol effects might still play a role here, just in a different way. There’s a condition called acquired hepatocerebral degeneration. This can happen in people with a history of liver disease due to alcohol, even years after they’ve quit. It can result in symptoms like these because of how substances get deposited in the brain.\\n\\nLinking this back to our patient, his history with alcohol could’ve led to some liver issues, and now, here we are with these symptoms showing up suddenly. Makes sense, right? So, considering everything, acquired hepatocerebral degeneration seems to fit quite nicely. That’s probably our most fitting diagnosis for this situation.\",\n 'Response': \"Considering the clinical presentation of sudden onset dysarthria, shuffling gait, and intention tremors in a 45-year-old man with a history of alcohol use who has been abstinent for the past 10 years, the most likely diagnosis is acquired hepatocerebral degeneration.\\n\\nThis condition is associated with chronic liver disease, which can often be a consequence of long-term alcohol use. Despite the patient's abstinence from alcohol for a decade, previous alcohol use may have led to underlying liver dysfunction. This dysfunction, even if subclinical, can cause encephalopathy due to the accumulation of neurotoxic substances that affect the brain. The sudden onset of these neurological symptoms aligns with how acquired hepatocerebral degeneration can manifest, making it a probable diagnosis in this scenario.\"}"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"#### Next step is to structure the fine-tuning dataset according to train prompt style—why?\n\n - Each question is paired with chain-of-thought reasoning and the final response.\n - Ensures every training example follows a consistent pattern.\n - Prevents the model from continuing beyond the expected response lengt by adding the EOS token.","metadata":{}},{"cell_type":"code","source":"# We need to format the dataset to fit our prompt training style \nEOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which the model when to stop generating text during training\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:14:17.690322Z","iopub.execute_input":"2025-02-08T12:14:17.690638Z","iopub.status.idle":"2025-02-08T12:14:17.696956Z","shell.execute_reply.started":"2025-02-08T12:14:17.690614Z","shell.execute_reply":"2025-02-08T12:14:17.696224Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Define formatting prompt function\ndef formatting_prompts_func(examples):\n    inputs = examples[\"Question\"]     # Get the medical question from the dataset\n    cots = examples[\"Complex_CoT\"]    # Get the chain-of-thought reasoning (logical step-by-step explanation)\n    outputs = examples[\"Response\"]    # Get the final model-generated response\n\n    texts = []\n\n    # Iterate over the dataset, formatting each question, reasoning step and response\n    for input, cot, output in zip(inputs, cots, outputs):\n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN # Insert values into our prompt template & append EOS token\n        texts.append(text)\n\n    return {\n        \"text\": texts # Return the newly formatted dataset with a \"text\" column containing structured prompts\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:15:43.743461Z","iopub.execute_input":"2025-02-08T12:15:43.743751Z","iopub.status.idle":"2025-02-08T12:15:43.749151Z","shell.execute_reply.started":"2025-02-08T12:15:43.743731Z","shell.execute_reply":"2025-02-08T12:15:43.748499Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Update dataset formatting\ndataset_finetune = dataset.map(formatting_prompts_func, batched=True)\ndataset_finetune[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:15:45.951503Z","iopub.execute_input":"2025-02-08T12:15:45.951788Z","iopub.status.idle":"2025-02-08T12:15:45.997638Z","shell.execute_reply.started":"2025-02-08T12:15:45.951768Z","shell.execute_reply":"2025-02-08T12:15:45.996969Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7972f625961c42328fe1422ca52bae69"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"Below is an instruction that describes a task, paired with an input that provides additional context. \\nGenerate a response that fully addresses the request with logical reasoning and medical expertise. \\nBefore answering, carefully analyze the question and construct a step-by-step chain of thoughts to ensure clarity, accuracy, and coherence.\\n\\n### Instruction:\\nYou are a highly skilled medical expert with deep expertise in clinical reasoning, diagnostics, and treatment planning. \\nProvide a well-structured, evidence-based response to the following medical question.\\n\\n### Question:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Response:\\n<think>\\nOkay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\\n</think>\\nCystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.<｜end▁of▁sentence｜>\""},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"### Step 3 - Setting up the model using LoRa\n#### An intuitive example of LoRa\nLLMs have **millions or even billions of weights** that determine how they process and generate text. When fine-tuning a model, we usually update all these weights, which requires **massive amounts of computational resources**.\n\nLoRa (**Low-Rank Adaptation**) allows to fine-tune efficiently by:\n\n- Instead of modifying all weights, **LoRa adds small, trainable adapters** to specific layers.\n- These adapters **capture task-specific knowledge** while leaving the original model unchanged.\n- This reduces the number of trainable parameters **by more than 90%**, making fine-tuning **much faster and memory-efficient**.\n\nThink of an LLM as a **complex factory**. Instead of rebuilding the entire factory to produce a new product, LoRa adds small, specialized tools to existing machines. This allows the factory to adapt quickly without disrupting its core structure.\n\nFor a more technical explanation, check out this tutorial by [Sebastian Raschka](https://www.youtube.com/watch?v=rgmJep4Sb4&t).\n\nBelow, we will use the `get_peft_model()` function which stands for Parameter-Efficient Fine-Tuning — this function wraps the base model (`model`) with LoRA modifications, ensuring that only specific parameters are trained.","metadata":{}},{"cell_type":"code","source":"# Apply LoRA (Low-Rank Adaptation) fine-tuning to the model \nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  # LoRA rank: Determines the size of the trainable adapters (higher = more parameters, lower = more efficiency)\n    target_modules=[  # List of transformer layers where LoRA adapters will be applied\n        \"q_proj\",   # Query projection in the self-attention mechanism\n        \"k_proj\",   # Key projection in the self-attention mechanism\n        \"v_proj\",   # Value projection in the self-attention mechanism\n        \"o_proj\",   # Output projection from the attention layer\n        \"gate_proj\",  # Used in feed-forward layers (MLP)\n        \"up_proj\",    # Part of the transformer’s feed-forward network (FFN)\n        \"down_proj\",  # Another part of the transformer’s FFN\n    ],\n    lora_alpha=16,  # Scaling factor for LoRA updates (higher values allow more influence from LoRA layers)\n    lora_dropout=0,  # Dropout rate for LoRA layers (0 means no dropout, full retention of information)\n    bias=\"none\",  # Specifies whether LoRA layers should learn bias terms (setting to \"none\" saves memory)\n    use_gradient_checkpointing=\"unsloth\",  # Saves memory by recomputing activations instead of storing them (recommended for long-context fine-tuning)\n    random_state=4056,  # Sets a seed for reproducibility, ensuring the same fine-tuning behavior across runs\n    use_rslora=False,  # Whether to use Rank-Stabilized LoRA (disabled here, meaning fixed-rank LoRA is used)\n    loftq_config=None,  # Low-bit Fine-Tuning Quantization (LoFTQ) is disabled in this configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:15:49.426963Z","iopub.execute_input":"2025-02-08T12:15:49.427270Z","iopub.status.idle":"2025-02-08T12:15:55.718845Z","shell.execute_reply.started":"2025-02-08T12:15:49.427248Z","shell.execute_reply":"2025-02-08T12:15:55.718161Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"Now, we initialize `SFTTrainer`, a supervised fine-tuning trainer from `trl` (Transformer Reinforcement Learning), to fine-tune our model efficiently on a dataset","metadata":{}},{"cell_type":"code","source":"# Initialize the fine-tuning trainer — Imported using from trl import SFTTrainer\ntrainer = SFTTrainer(\n    model=model_lora,  # The model to be fine-tuned\n    tokenizer=tokenizer,  # Tokenizer to process text inputs\n    train_dataset=dataset_finetune,  # Dataset used for training\n    dataset_text_field=\"text\",  # Specifies which field in the dataset contains training text\n    max_seq_length=max_seq_length,  # Defines the maximum sequence length for inputs\n    dataset_num_proc=2,  # Uses 2 CPU threads to speed up data preprocessing\n\n    # Define training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,  # Number of examples processed per device (GPU) at a time\n        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps before updating weights\n        num_train_epochs=1, # Full fine-tuning run\n        warmup_steps=5,  # Gradually increases learning rate for the first 5 steps\n        max_steps=60,  # Limits training to 60 steps (useful for debugging; increase for full fine-tuning)\n        learning_rate=2e-4,  # Learning rate for weight updates (tuned for LoRA fine-tuning)\n        fp16=not is_bfloat16_supported(),  # Use FP16 (if BF16 is not supported) to speed up training\n        bf16=is_bfloat16_supported(),  # Use BF16 if supported (better numerical stability on newer GPUs)\n        logging_steps=10,  # Logs training progress every 10 steps\n        optim=\"adamw_8bit\",  # Uses memory-efficient AdamW optimizer in 8-bit mode\n        weight_decay=0.01,  # Regularization to prevent overfitting\n        lr_scheduler_type=\"linear\",  # Uses a linear learning rate schedule\n        seed=4056,  # Sets a fixed seed for reproducibility\n        output_dir=\"outputs\"  # Directory where fine-tuned model checkpoints will be saved\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:15:58.500100Z","iopub.execute_input":"2025-02-08T12:15:58.500422Z","iopub.status.idle":"2025-02-08T12:15:58.772760Z","shell.execute_reply.started":"2025-02-08T12:15:58.500397Z","shell.execute_reply":"2025-02-08T12:15:58.772110Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### Step 4 - Model training\nThis should take around 30 to 40 minutes - we can then check out our training results on Weights and Biases","metadata":{}},{"cell_type":"code","source":"# Start the fine-tuning process\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:16:03.577905Z","iopub.execute_input":"2025-02-08T12:16:03.578258Z","iopub.status.idle":"2025-02-08T12:41:39.056150Z","shell.execute_reply.started":"2025-02-08T12:16:03.578219Z","shell.execute_reply":"2025-02-08T12:41:39.055366Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 500 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 25:04, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.916600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.396700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.402400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.337100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.304300</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.299800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:42:57.427254Z","iopub.execute_input":"2025-02-08T12:42:57.427599Z","iopub.status.idle":"2025-02-08T12:42:58.988563Z","shell.execute_reply.started":"2025-02-08T12:42:57.427576Z","shell.execute_reply":"2025-02-08T12:42:58.987879Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▄▂▃▂▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1.824470363111424e+16</td></tr><tr><td>train/epoch</td><td>0.96</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.23267</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.2998</td></tr><tr><td>train_loss</td><td>1.44281</td></tr><tr><td>train_runtime</td><td>1531.4618</td></tr><tr><td>train_samples_per_second</td><td>0.313</td></tr><tr><td>train_steps_per_second</td><td>0.039</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">smart-wildflower-2</strong> at: <a href='https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/ozw6z49o' target=\"_blank\">https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset/runs/ozw6z49o</a><br> View project at: <a href='https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset' target=\"_blank\">https://wandb.ai/uozbek-havelsan/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Medical%20COT%20Dataset</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250208_121156-ozw6z49o/logs</code>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"### Step 5 - Run model inference after fine-tuning","metadata":{}},{"cell_type":"code","source":"question = \"\"\"A 45-year-old man presents with progressive difficulty swallowing both solids and liquids over the past \n              six months. He reports occasional regurgitation of undigested food and a sensation of food sticking in his \n              chest. A barium swallow study reveals a dilated esophagus with a bird’s beak appearance at the lower \n              esophageal sphincter. What would esophageal manometry most likely demonstrate regarding lower esophageal \n              sphincter pressure and peristalsis?\"\"\"\n\n# Load the inference model using FastLanguageModel (Unsloth optimizes for speed)\nFastLanguageModel.for_inference(model_lora)  # Unsloth has 2x faster inference!\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                        # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:43:47.397752Z","iopub.execute_input":"2025-02-08T12:43:47.398062Z","iopub.status.idle":"2025-02-08T12:44:18.369570Z","shell.execute_reply.started":"2025-02-08T12:43:47.398029Z","shell.execute_reply":"2025-02-08T12:44:18.368761Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nAlright, let's think about this. This guy is 45 and has been struggling with swallowing stuff for six months now. Sounds like he's having trouble with both solids and liquids, which is a bit unusual. He's also complaining about regurgitating undigested food, which means it's not getting through the digestive system properly. \n\nWhen they looked at his esophagus with a barium swallow study, they saw a dilated esophagus and something called a bird’s beak appearance at the lower esophageal sphincter. That bird’s beak thing sounds familiar. It’s often linked to a condition called achalasia, where the sphincter doesn’t open properly and the esophagus doesn’t move properly due to a lack of cholecystokinin, a hormone needed for sphincter function and esophageal peristalsis.\n\nNow, thinking about manometry, it’s like checking the pressure and movement of the sphincter. In achalasia, the sphincter is usually not moving properly. So, if we look at the pressure readings, they might show lower than normal pressure at the sphincter. Also, the muscle contractions, or peristalsis, might not be happening in a normal way because the sphincter is not opening up. \n\nGiven that, I’d expect the manometry to show lower esophageal sphincter pressure and a decrease in peristalsis. This would make sense for a condition like achalasia. It's a pretty common finding in this kind of situation, so I’m pretty confident about this.\n</think>\nEsophageal manometry would most likely demonstrate lower esophageal sphincter pressure and decreased peristalsis. This is consistent with the findings of a bird’s beak appearance at the lower esophageal sphincter, which is a hallmark of achalasia. Achalasia is characterized by a failure of the lower esophageal sphincter to relax and open properly, leading to impaired sphincter function and a lack of peristalsis, or esophageal muscle contractions. Therefore, the decreased pressure and altered peristalsis observed in manometry align with this condition.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"question = \"\"\"A 67-year-old woman with a history of chronic kidney disease presents with progressive bone pain and muscle weakness. \n              Laboratory studies reveal hypocalcemia, hyperphosphatemia, and elevated parathyroid hormone levels. \n              Radiographic imaging shows subperiosteal bone resorption, particularly in the phalanges. \n              What is the underlying pathophysiological mechanism responsible for this patient's condition?\"\"\"\n\n# Load the inference model using FastLanguageModel (Unsloth optimizes for speed)\nFastLanguageModel.for_inference(model_lora)  # Unsloth has 2x faster inference!\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                        # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-08T12:44:18.370537Z","iopub.execute_input":"2025-02-08T12:44:18.370830Z","iopub.status.idle":"2025-02-08T12:44:49.693607Z","shell.execute_reply.started":"2025-02-08T12:44:18.370807Z","shell.execute_reply":"2025-02-08T12:44:49.692790Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, let's think about this. We have a 67-year-old woman with chronic kidney disease, and she's showing symptoms like bone pain and muscle weakness. These symptoms seem to be progressing, which is worrying. Let's look at her labs. She's hypocalcemic, meaning she's not getting enough calcium. Her phosphorus levels are high, which is also a bit concerning. And her parathyroid hormone levels are up, which means her kidneys are working hard to try to maintain calcium levels. That's a bit of a puzzle.\n\nNow, looking at the imaging, she's showing subperiosteal bone resorption, particularly in her phalanges. This sounds like something like osteitis or maybe some kind of metabolic bone disease. Since her parathyroid hormone is high, it's pointing towards something related to parathyroid activity.\n\nI remember that chronic kidney disease can lead to secondary hyperparathyroidism because the kidneys are not working well and can't activate vitamin D properly. This leads to a loop where the body's trying to maintain calcium levels, which can cause bone issues.\n\nSo, putting this together, her symptoms, labs, and imaging point towards this being a case of secondary hyperparathyroidism caused by chronic kidney disease. This makes sense because it's a common issue in people with kidney problems. The high parathyroid hormone is trying to manage calcium levels, but it's causing bone issues, which is what we see in the imaging.\n\nYeah, I think that's it. The high parathyroid hormone levels and the bone changes are classic signs of secondary hyperparathyroidism due to chronic kidney disease.\n</think>\nThe underlying pathophysiological mechanism responsible for this patient's condition is secondary hyperparathyroidism due to chronic kidney disease. Chronic kidney disease can lead to secondary hyperparathyroidism due to the kidneys' inability to activate vitamin D and excrete phosphorus, which results in elevated parathyroid hormone levels. This condition can cause bone demineralization, leading to subperiosteal bone resorption, particularly in the phalanges, which aligns with the imaging findings.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Conclusion\nFine-tuning DeepSeek R1 significantly improved its ability to generate structured, concise, and medically accurate responses. By leveraging Unsloth, Hugging Face Transformers, and Kaggle’s GPU resources, we optimized training efficiency while enhancing the model’s clinical reasoning and diagnostic accuracy. The results demonstrate fine-tuning’s potential in medical Q&A, decision support, and automated documentation. Future work could involve larger datasets, reinforcement learning, or integrating real-world medical cases to further refine accuracy and adaptability, making the model a valuable tool for AI-driven medical assistance.","metadata":{}}]}